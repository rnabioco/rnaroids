shell.executable("/bin/bash")
shell.prefix("source ~/.bash_profile; ")
from os import path
from glob import glob
import sys

""" Snakemake pipeline for RNA metabolism processing """ 

configfile: "config_rnaseq.yaml"
  
DATA = config["DATA"]
SRC = config["SRC"]
DBASES = config["DBASES"]
METADATA = config["METADATA"]
TRANSCRIPTS = config["TRANSCRIPTS"]
GENOME = config["GENOME"]
GENOME_DIR = config["GENOME_DIR"]
CHROM_SIZES = config["CHROM_SIZES"]
TRANSCRIPTS_FA = config["TRANSCRIPTS_FA"]
TRANSCRIPTS_BED = config["TRANSCRIPTS_BED"]
SALMON_IDX = config["SALMON_IDX"]
KALLISTO_IDX = config["KALLISTO_IDX"]
SPLICE_JUNCTS = config["SPLICE_JUNCTS"]
P5TRIM = config["5P"]

ERCC_FA = config["ERCC_FA"]
ERCC_GTF = config["ERCC_GTF"]
RRNA_FA = config["RRNA_FA"]

READ = ['R1', 'R2']

# find all splice junction files (no error if none)
# if no splice junctions have been generated, then run pipeline through
# star mapping. Then rerun with the produced splice junctions

SPLICE_JUNCTS = config["SPLICE_JUNCTS"]
if SPLICE_JUNCTS: 
  # make a string with filenames seperated by whitespace
  SPLICE_JUNCTS = glob(SPLICE_JUNCTS)
  SPLICE_JUNCTS = " ".join(SPLICE_JUNCTS)

SAMPLE, READ_ID = glob_wildcards(path.join(DATA, "fastq",
                    "raw_data","{fq}_R{read}.fastq.gz"))

# build list of chromosome for parallel execution over chromosomes
#CHROMS = [] 
#with open(CHROM_SIZES) as f:
#  for line in f:
#    try: 
#      chrom = line.split("\t")[0]
#    except IndexError:
#      sys.exit("{} chromsome entries are not properly formatted".format(CHROM_SIZES))
#    
#    CHROMS.append(chrom)

rule all:
  input:
    #### qc ####
    expand("{data}/qc/fastqc/{sample}_{read}_fastqc/summary.txt",
    data=DATA, sample = SAMPLE, read = READ),
    expand("{data}/qc/rseqc/{sample}_{reports}.txt",
    data=DATA, sample = SAMPLE, reports = ["bam_stat", "lib_type", "read_dist"]),

    #### extract UMIs and trim ####
    expand("{data}/fastq/filtered/{sample}_{read}_umi_trim_noercc.fastq.gz",
    data=DATA, sample = SAMPLE, read = READ),
    
    #### index and align data to erccs and rRNA####
    expand("{data}/fastq/filtered/erccs/{sample}_ercc.bam", 
    data=DATA, sample = SAMPLE),
    [(DBASES + "/ercc/bowtie_idx/erccrRNA.{}.ebwt".format(x)) for x in [1, 2, 3, 4, "rev.1", "rev.2"]],

    #### star two-pass alignments ####
    expand("{data}/star/dedup/{sample}_dedup.bam",
            data=DATA, sample = SAMPLE),
    expand("{data}/fastq/dedup/{sample}_{read}.fastq.gz",
            data=DATA, sample = SAMPLE, read = ["R1", "R2", "singletons"]),
    expand("{data}/star/firstpass/{sample}.bam",
            data=DATA, sample = SAMPLE),

    #### salmon alignments ####
    expand("{data}/salmon/{sample}/quant.sf", 
    data=DATA, sample = SAMPLE),
    
    #### bigwigs ####
    expand("{data}/bigwigs/{sample}_{orient}.bw",
    data=DATA, sample = SAMPLE, orient = ["fwd", "rev", "rev_neg"]),
    
    #### count erccs ####
    expand("{data}/ercc/ercc_counts.txt", data=DATA)
   
include: "rules/umi_extract_trim.snake"
include: "rules/rRNA_ercc_removal.snake"
include: "rules/star_idx.snake"
include: "rules/star.snake"
include: "rules/salmon.snake"    
include: "rules/make_bigwigs.snake"
include: "rules/qc.snake"
include: "rules/ercc_dedup_and_count.snake"
